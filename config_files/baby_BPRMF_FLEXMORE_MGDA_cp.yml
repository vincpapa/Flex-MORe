setting:
  data: amazon_baby # Dataset
  gpu_id: 0 # GPU_ID
  baseline: BPRMF # Base model
  wrapper: FLEXMORE_MGDA # Multi-Objective Method
  epochs: 500 # Number of epochs
  validation_rate: 10 # Period of evaluation during training
  validation_metric: ndcg@20 # Metric of evaluation during training
  batch_size: 2048 # Batch size
hyperparameters:
  seed: [7, 82, 185] #42
  dim: [64] # Dimension for embedding
  lr: [0.005] # Learning rate
  l_2: [0.01] #L2 penalty
  mode: [rpm] # Which loss to use
  g_n: [loss+] # Modality of gradient normalization
  atk: [{atk_cons: 20, atk_prov: 20}] # Cutoff when computing approximated metrics
  ranker: [AIMLE]




