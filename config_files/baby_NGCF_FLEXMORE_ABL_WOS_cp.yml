setting:
  data: amazon_baby # Dataset
  gpu_id: 3 # GPU_ID
  baseline: NGCF # Base model
  wrapper: FLEXMORE_ABL_WOS # Multi-Objective Method
  epochs: 300 # Number of epochs
  validation_rate: 10 # Period of evaluation during training
  validation_metric: ndcg@20 # Metric of evaluation during training
  batch_size: 2048 # Batch size
hyperparameters:
  dim: [64] # Dimension for embedding
  lr: [0.001] # Learning rate
  l_2: [0.005] #L2 penalty
  mode: [rpms] # Which loss to use (MPR-rpa)
  g_n: [loss+] # Modality of gradient normalization
  atk: [20] # Cutoff in metrics approximation
  ranker: [AIMLE] # Which Ranking Approx. to use (AIMLE -> MPR)
  layers: [3]
  message_dropout: [0.1]
  node_dropout: [0.1]
  normalize: [True]
  scale: [0.75]
